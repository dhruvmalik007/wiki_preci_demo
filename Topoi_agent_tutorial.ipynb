{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfmwRG97gOkdtywJKQpwwq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4eb285186859482fb62076d05f803877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e539972daf50497a9383815b657c77a2",
              "IPY_MODEL_d6ae2d16b3fc4304a1871b107731f1e1",
              "IPY_MODEL_1dbb6dca5170466e9d9d4b31b23f8275",
              "IPY_MODEL_95bfd90e67b44a1292a7e47321017db8",
              "IPY_MODEL_d5a2cef608214580a2f15f8d446df9a2"
            ],
            "layout": "IPY_MODEL_40da8f0c3dc84126b3099db8cd0a9e35"
          }
        },
        "e539972daf50497a9383815b657c77a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f175adc65844192867bcd8469231502",
            "placeholder": "​",
            "style": "IPY_MODEL_5397677d1046415b97c78425cc3359b8",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "d6ae2d16b3fc4304a1871b107731f1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_dd6e9bf7a7834005b6174931edf1950f",
            "placeholder": "​",
            "style": "IPY_MODEL_837bf7f5b0fc483e9d64bdc1ede58837",
            "value": ""
          }
        },
        "1dbb6dca5170466e9d9d4b31b23f8275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_06ae7f7d7db94096a63b2ddfebc530b2",
            "style": "IPY_MODEL_9a404e3ac7d8403091946da8114379a5",
            "value": true
          }
        },
        "95bfd90e67b44a1292a7e47321017db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_975d11f1067140bda2a11ccb185f9517",
            "style": "IPY_MODEL_0a34d3d6a10947bd9f2db9e2b91e4998",
            "tooltip": ""
          }
        },
        "d5a2cef608214580a2f15f8d446df9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5796bfee463b419e9a7e0b7f8f4bc365",
            "placeholder": "​",
            "style": "IPY_MODEL_6c070aa3be104fb9bf211883f59104c2",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "40da8f0c3dc84126b3099db8cd0a9e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "3f175adc65844192867bcd8469231502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5397677d1046415b97c78425cc3359b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd6e9bf7a7834005b6174931edf1950f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "837bf7f5b0fc483e9d64bdc1ede58837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06ae7f7d7db94096a63b2ddfebc530b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a404e3ac7d8403091946da8114379a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "975d11f1067140bda2a11ccb185f9517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a34d3d6a10947bd9f2db9e2b91e4998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5796bfee463b419e9a7e0b7f8f4bc365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c070aa3be104fb9bf211883f59104c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruvmalik007/wiki_preci_demo/blob/main/Topoi_agent_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Topoi Discussion agent tutorial\n",
        "\n",
        "\n",
        "This is the tutorial for the researchers to try to come up with a discussion quorum agent that\n",
        "\n"
      ],
      "metadata": {
        "id": "sCAxCsN0Cu0B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2c36KRchCkM",
        "outputId": "b6c2cb31-63b1-41ee-8360-98ad6c3fc96d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: langchain_experimental in /usr/local/lib/python3.10/dist-packages (0.0.61)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.9)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.81)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.4.1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.35.3)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.0.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.19.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.15.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain_community) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (9.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.5.40)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "## installing the required libraries.\n",
        "!pip install langchain_community langchain_openai langchain langgraph langchain_experimental wikipedia langchain-huggingface huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## also fetching the env vars for accessing the openai / tavily or other services\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login(write_permission=True)"
      ],
      "metadata": {
        "id": "6F0ahvA9hzQX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "4eb285186859482fb62076d05f803877",
            "e539972daf50497a9383815b657c77a2",
            "d6ae2d16b3fc4304a1871b107731f1e1",
            "1dbb6dca5170466e9d9d4b31b23f8275",
            "95bfd90e67b44a1292a7e47321017db8",
            "d5a2cef608214580a2f15f8d446df9a2",
            "40da8f0c3dc84126b3099db8cd0a9e35",
            "3f175adc65844192867bcd8469231502",
            "5397677d1046415b97c78425cc3359b8",
            "dd6e9bf7a7834005b6174931edf1950f",
            "837bf7f5b0fc483e9d64bdc1ede58837",
            "06ae7f7d7db94096a63b2ddfebc530b2",
            "9a404e3ac7d8403091946da8114379a5",
            "975d11f1067140bda2a11ccb185f9517",
            "0a34d3d6a10947bd9f2db9e2b91e4998",
            "5796bfee463b419e9a7e0b7f8f4bc365",
            "6c070aa3be104fb9bf211883f59104c2"
          ]
        },
        "outputId": "683a8b08-badc-492c-cb52-7447aa542210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4eb285186859482fb62076d05f803877"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.tools import wikipedia\n",
        "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.agents import load_tools, AgentExecutor, create_openai_tools_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_huggingface import ChatHuggingFace\n",
        "from langchain_core.messages import BaseMessage, ToolMessage, HumanMessage, ChatMessage\n",
        "from langchain_core.prompts.chat import MessagesPlaceholder, ChatPromptTemplate\n",
        "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "import functools\n",
        "from langgraph.graph import END, StateGraph\n",
        "from typing import Sequence, TypedDict, Annotated\n",
        "import operator\n",
        "import os\n",
        "import getpass\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper"
      ],
      "metadata": {
        "id": "e56yflZziJ7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## making huggingface endpoint function in order to call freely available server inferrencing alternatives\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain.agents import tool\n",
        "\n",
        "# from huggingface_hub import login\n",
        "# login(token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"])\n",
        "\n",
        "## Important , you need to validate the ToC for certain models\n",
        "## and get the API token in order to get the result.\n",
        "\n",
        "huggingfaceEndpoint = HuggingFaceEndpoint(\n",
        "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=1000,\n",
        "    huggingfacehub_api_token=\"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\",\n",
        "    do_sample=False,\n",
        ")\n",
        "\n",
        "@tool\n",
        "def get_huggingface_invokation(query):\n",
        "  \"\"\"\n",
        "  function for generating the queries from the llm model\n",
        "  \"\"\"\n",
        "  return huggingfaceEndpoint.invoke(query)\n",
        "\n",
        "huggingfacellm = ChatHuggingFace(llm=huggingfaceEndpoint)\n",
        "\n",
        "\n",
        "\n",
        "## also defining the response result pattern:\n",
        "\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "class HuggingfaceResponse():\n",
        "    role: float = Field(description=\"role of the responder\")\n",
        "    response: str = Field(description=\"giving the response regarding the weather\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FpwCb9VjHUrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556ffe15-f961-4c0e-cda3-ed625e82e07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## adding langchain memory functions in order to excute the agent operations with memory.\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "def register_memory(memory, category):\n",
        "  if category == \"Input-topic\":\n",
        "    memory.add_user_message(memory)\n",
        "\n",
        "  if category == \"agents\":\n",
        "    memory.add_ai_message(memory)"
      ],
      "metadata": {
        "id": "iyALVzNwM4kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def scraping_agent(llm, tools, system_message: str):\n",
        "  \"\"\"\n",
        "  define the agent specialised with the addressing queries with context related to the wikipedia\n",
        "  \"\"\"\n",
        "  topoi_categories = [\"Comparison\", \"Cause & Effect\", \"Logical\", \"Ethical\", \"Slippery Slope\", \"Appeal to Authority\", \"Appeal to Emotion\"]\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_messages(\n",
        "      [\n",
        "          (\n",
        "              \"system\"\n",
        "              \"You are helpful AI assistant specilizing in constructing arguments as topoi and collaborating with other assistants \"\n",
        "              \"Use the provided search tool to check for the given topic online and give the feedback, or giving contradiction provided by another.\"\n",
        "              \"you always need to cite the statistics with clear references and dont repeat the discussions on other topics\"\n",
        "              \"JUST RESPOND TO THE QUERY AND DONT STATE THE FACTS\"\n",
        "              \"try to give as many hypothesis to support your response (at least 3) on each topic with reason\"\n",
        "              \"You will be provided with the topic : {topoi_category},\"\n",
        "              \"dont deviate much your answer around the topic and be precise\"\n",
        "              \"you will have to organise discussion for a topoi between assistant for 5 rounds checking the discussions of your corresponding researcher/ critic agent collague \"\n",
        "              \"AND MOST IMP:  Use as much facts from the news sources (WITH NUMBERS) as possible\"\n",
        "              \"prefix your response with FINAL ANSWER so all the subordinate teaam discussing with you knows when to stop after the 3 round discussion and shift to next discussion.\"\n",
        "              \"You have access to the following tools: {tool_names}.\\n{system_message}\"\n",
        "          ),\n",
        "          MessagesPlaceholder(variable_name=\"messages\"),\n",
        "      ]\n",
        "  )\n",
        "  prompt = prompt.partial(system_message=system_message)\n",
        "  prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]), topoi_category=\",\".join([_topoi for _topoi in topoi_categories]))\n",
        "  return prompt | openaiLLM.bind_tools(tools + [HuggingfaceResponse])\n",
        "\n",
        "\n",
        "\n",
        "def wikipedia_result(query):\n",
        "  wikipediaQuery = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "  return wikipediaQuery.run(query)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xQkRWDODzZZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.tools import tool\n",
        "from langchain_experimental.utilities import PythonREPL\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n"
      ],
      "metadata": {
        "id": "I4Q-6ju4EWKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## creating the agent operation\n",
        "\n",
        "import operator\n",
        "from typing import Annotated, Sequence, TypedDict\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# This defines the object that is passed between each node\n",
        "# in the graph. We will create different nodes for each agent and tool\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "    sender: str\n"
      ],
      "metadata": {
        "id": "1apU_wS7Gx6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "from langchain_core.messages import AIMessage\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "# Helper function to create a node for a given agent\n",
        "def agent_node(state, agent, name):\n",
        "    result = agent.invoke(state)\n",
        "    # We convert the agent output into a format that is suitable to append to the global state\n",
        "    if isinstance(result, ToolMessage):\n",
        "        pass\n",
        "    else:\n",
        "        result = AIMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
        "    return {\n",
        "        \"messages\": [result],\n",
        "        # Since we have a strict workflow, we can\n",
        "        # track the sender so we know who to pass to next.\n",
        "        \"sender\": name,\n",
        "    }\n",
        "\n",
        "llm = huggingfacellm\n",
        "\n",
        "openaiLLM = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "wikipediaTools = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "\n",
        "# Research agent and node\n",
        "research_agent = scraping_agent(\n",
        "    llm,\n",
        "    [tavily_tool],\n",
        "    system_message=\"You should provide the accurate topoi responses based on the given topic and  to your subordinate discussion.\",\n",
        ")\n",
        "\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
        "\n",
        "\n",
        "\n",
        "# chart_generator\n",
        "chart_agent = scraping_agent(\n",
        "    llm,\n",
        "    [wikipediaTools],\n",
        "    system_message=\"the responses that you generate visible to the user with that of researcher.\",\n",
        ")\n",
        "critic_node = functools.partial(agent_node, agent=chart_agent, name=\"critic_node\")\n",
        "\n"
      ],
      "metadata": {
        "id": "l4nknURAIAnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## defining the supervisor node that will be managing the running of the subordinate nodes\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from typing import Literal\n",
        "\n",
        "tools = [tavily_tool, wikipediaTools]\n",
        "supervisor_node = ToolNode(tools)\n",
        "\n",
        "\n",
        "#  Here Either agent can decide to end based on their topoi result\n",
        "# but both will be synchronously generating the result for the specific topoi topic argument at same time\n",
        "\n",
        "def router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n",
        "    # This is the router\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    if last_message.tool_calls:\n",
        "        # The previous agent is invoking a tool\n",
        "        return \"call_tool\"\n",
        "    if \"FINAL ANSWER\" in last_message.content:\n",
        "        # Any agent decided the work is done\n",
        "        return \"__end__\"\n",
        "    return \"continue\"\n"
      ],
      "metadata": {
        "id": "RAAdSuRiK6Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"Researcher\", research_node)\n",
        "workflow.add_node(\"critic_node\", critic_node)\n",
        "workflow.add_node(\"call_tool\", supervisor_node)\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "   \"Researcher\",\n",
        "    router,\n",
        "    {\"continue\": \"critic_node\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"critic_node\",\n",
        "    router,\n",
        "    {\"continue\": \"Researcher\", \"call_tool\": \"call_tool\", \"__end__\": END},\n",
        ")\n",
        "\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"call_tool\",\n",
        "    # Each agent node updates the 'sender' field\n",
        "    # the tool calling node does not, meaning\n",
        "    # this edge will route back to the original agent\n",
        "    # who invoked the tool\n",
        "    lambda x: x[\"sender\"],\n",
        "    {\n",
        "        \"Researcher\": \"Researcher\",\n",
        "        \"critic_node\": \"critic_node\",\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "workflow.set_entry_point(\"Researcher\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AxwWwvZoL_xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## showcasing the workflow of the graph:\n",
        "\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "1Q_y4wUfNbL-",
        "outputId": "9b95f90d-3236-4025-96aa-03ea32d8576f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAFBAVEDASIAAhEBAxEB/8QAHQABAAIDAQEBAQAAAAAAAAAAAAYHBAUIAwIJAf/EAFcQAAEDBAADAwYHCA8FBgcAAAECAwQABQYRBxIhEyIxCBQVFkFRFzJVYZPR0iNCVFZxgZGUCTM1NlNyc3WSlaKxs7ThJDdSYqElQ3R2gsImNIOWxNTw/8QAGwEBAAIDAQEAAAAAAAAAAAAAAAEDAgQFBgf/xAA7EQEAAQIBBwgHCQADAQAAAAAAAQIDEQQSFCExUZETFUFSU2Gh0nGSscHR4fAFIjIzQmJjgaJyssLx/9oADAMBAAIRAxEAPwD9U6UpQKUpQKUpQKUpQKx5txi21tLkuSzFbUeULecCAT7tmsiq/wCK0ZqXLxNp9pDzZuLm0OJCgf8AZX/YamMIiaqtkRM8Imfcst0cpXFO9K/WqyfLED9aR9dPWqyfLED9aR9dV56v2v5Nh/QJ+qnq/a/k2H9An6q5HOuT9SrjDq83fu8Fh+tVk+WIH60j66etVk+WIH60j66rz1ftfybD+gT9VPV+1/JsP6BP1U51yfqVcYObv3eCw/WqyfLED9aR9dPWqyfLED9aR9dV56v2v5Nh/QJ+qnq/a/k2H9An6qc65P1KuMHN37vBYfrVZPliB+tI+unrVZPliB+tI+uq89X7X8mw/oE/VT1ftfybD+gT9VOdcn6lXGDm793gsP1qsnyxA/WkfXT1qsnyxA/WkfXVeer9r+TYf0CfqrU5hYra3iV7Wi3xUrTBfIUlhIIPZq6+FW2vtLJ7tymjNnXMRtjpJ+z8Ixzl2gggEHYPtFf2se3fufG/kk/3CsiulMYTg4xSlKgKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKgfE/90MS/nFz/KP1PKgfE/8AdDEv5xc/yj9Kvy7n/Gv/AKy2Mn/Op9LDpWpyPLLHh0JuZf7zb7HEccDSJFylIjtqWQSEhSyATpJOvHQPuqPDjlw4UCRxAxYhI2SL1G6D+nXgooqnXEPUzVTGqZbjPM3tnDnErjkd4Lot8FCVOBhvncWVKCEJSn2lSlJA8Bs9SKrbiJx1vGPYbZ7xbsLvkWVKyCHaXoNzjMoeDbjjYUUDtwklYVyIUFFPP8bQBI32T8RcOzvG7nZLHNxviHPlMFIxti8xiqYjY5x8YgaTtWyPFI6jxFaMcMM+d4Yz4yba+2q3ZLBvNgxu6XVEmQ1FjuMuKjKk8ykjmKXOQFSgkEAq92zaopjCa4149LXuVVT+Dd0LayLik/jlstcpWEZXcXprKnlw7fDaediBOth4h3kCuvRKVKJ0db0a1U/yhcdaRh/oyBd8hcyyG9NtTVrjIUpxLQbK0q51o5Fac++0Byq2R03E8/xjKc5yfH71eOH7uQWMW15lWKyrrHS3Cndt3ZD/AH+zdSWwACnnKNnSSTWHwh4UZVis7hMm62lEZvGrZeYE51uS0tCVOvMlhSNK5lJWlCiOmxrSgDUxRbinGduvp7p+SJruZ2EbPR6PmlWMcZb3e+M18xR/EbqxbIsKA82+URwqKp5LylqkHtz3TyJSnkSo7QvfTRNvVUsq25DhnHC9ZIzZBdMav1ugx5dwTNZY9GGOt7nW4lxQKkcjvNtGz3SNe2pEOOfDcn/eDiv9dRvt1VcpzpiaI1YRsWUVYYxXPTKcVpsz/efff/AP/wCGqtCnjlw4WoJTxAxZSidAC9RiSf6db7M/3n33/wAA/wD4aqsyamacot4x0x7Vk1RMThK2bd+58b+ST/cKyKx7d+58b+ST/cKyK9tVtl48pSlYhSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBUD4n/uhiX84uf5R+p5WkyjEoeWNQ0SnZLCojxfadiu9mtKihSD193KoipiIqiqmZwxiqOMTHvW2qooriqehD3WW3khLiEuAHelDdeXmEX8GZ/oCt18FMH5Yvf67/pT4KYPyxe/13/SuBzRPaxwl2tPtbpaduIw0rmQy2hXvSkA17Vsvgpg/LF7/AF3/AEp8FMH5Yvf67/pTmf8AljhJzha3S1tKrTyn4kzhTw7gXiw3u6NzXr3AgrL8jtE9k68ELGteOj41bvwUwfli9/rv+lOZ/wCWOEp5wtbpawgKBBGwfEGvA2+KR/8ALM/Rit18FMH5Yvf67/pT4KYPyxe/13/SnNH8scJRzha3S0vmEb8Ha/oCtdmf7z77/wCAf/w1VK/gpg/LF7/Xf9K8pPCC2TIzsd+63pxl1BbWhU3opJGiD091XWfsvk7tNc3Y1TE7J6ETl9qYwwlM7d+58b+ST/cKyK+Gm0stIbT8VCQkb9wr7rszOM4uCUpSoClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUHO/l0f7nbT/AOZ7T/mBXRFc7+XR/udtP/me0/5gV0RQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQc7+XR/udtP8A5ntP+YFdEVyZ5bvFnB5/DqNZIuZY/JvMLJ7f51bmbowuRH7KSO152wvmTyaPNsDl0d6rozGeKOGZrOELHsusV+mFgyhHtlyZkuFkL5C5yoUTyBZ5Srw308aCT0pSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpUSvvEKNbpbsG3Q3rzPaPK4lkhDLJ9y3VdN+9KeZQ9oG6zpoqr2Mqaaq5wpjFLaVW6s2yxzZTAs0f/AJC+67r/ANXKnf6K+fXLLvwey/peqzkv3RxbOiXtyyqVWvrll34PZf0vU9csu/B7L+l6nJR1o4p0S9ufl/8AsgHBl/hVx/u1zbStVmypxy8xXlHf3VatyGyfeHFFWvYlxFdhfsaXAs4DwrkZxc4xbvWU8qo/OO81BSfuevd2itr9xSGz7KmHHrhUryjMet1oyqNBaat8sS2JNvdW2+k6IUjmUlXcUCNjX3qTsECrHt+R5LaoEaFDg2KNEjNJZZZb7UJbQkAJSB7AAAKclHWjiaJe3LRpVa+uWXfg9l/S9T1yy78Hsv6XqclHWjiaJe3LKpVa+uWXfg9l/S9Xsxn+QxXAZlkhTWN9TAmFLoHzIcSEn86xTkt1UcfiiclvR+lYlK1WPZNAyaMt2E4sLbIS9HebLbrKvcpCuo+Y+B8QSOtbWqqqZpnCqGrMTE4SUpSsUFKUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoIjn99fhtw7TBdUzNuHOVvNq0thhIHOtP/NtSEj3Fe/ZUaixWoUdDDCA20gaSkf/AN1Pz165OsucS5qV+DVpiFse7mek8x/PyJ/oilWXvuxFuN0T/c6/ZqegyOiKbcVdMq0xnykOHWXXqHarbkXNNmOKZipkwZMZEhwEgobcdbShatgjQJJqy64n4bSr3kWIcH8UvUCDZcSfv7s+HfhIU87JkRpTrqIvJyJDK3FcwBKlbCVa6nVSbEzxX4p2t/MLJN81ua7pIQx2+TutRIqGZKm/N3LeIqkEciNEqWVnm5uYbAGvgyovTMa4xdZUrns3C98PuLlwlZdMyGWLpNlKxxyJcSq0yEBhSm4LsYftbqQlRCuXvlO+b2VHOE8Tipm9tw/OItzC/ST7E2e8/k7rsV6MpX3ZhMDzUNtEJ5kp5V8yVJG1K67jBZyuvDDW6npXKcjLr8c2x3Msel5CMXumXos6nrtfe0YltLfWy4lqBycrbaVJVyL5gvuAkHe63NluF5tuNcXs8dvl6utwxu8XsWq2OT3fM2kNIVyoUyFacSCdgK2EhI5QnXVgReieh0TdbnGslrmXGa72MOIyuQ+5ylXIhCSpR0ASdAHoBuv5Z7vEv9og3SA728GawiTHd5SnnbWkKSrRAI2CDogGqXjYKu38HrvkkjMcgyOdcMXkPSDNuKnIby3IxWVtsa5GwOvKEaAB678aieFC6cM08HZcG/Xu8MZDY3kTbXPll5hRat3nLXYt600QW+QcgGweuz1I5SYmMY1On6VyxwnicVM3tuH5xFuYX6SfYmz3n8nddivRlK+7MJgeahtohPMlPKvmSpI2pXXc84CWmdfZmTZFdsivdxfi5Pd4cOG9cXfNWGESHEJQWt8q9ddFQPL3QnQFE03c7DCNq35nnUB5F0toPpKMklCArlTIT4lpfvB9m/A6I8Ks+03OPerXEuERfPGlNJebV70qGx/fVeVveEyyrC0JPVDU6c037O4mW6lI/MBr81bVP3rUzPRMeOPw9rn5dRGEVxtTGlKVU5BSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKCBcRYCoNzt9+SD5ulCoUw70EIUeZtw/MlQKfm7XfgK11WW8y3JZcadbS604koWhY2lQPQgg+IqvbnhF1si1KsgauNu+9t77nZvM/M24dhSfclXLr/iPQC6Yi7ERjhMeP17PHqZLlNNEZlaDK4RYkrBmMPNp/8Ah6O6H2YwkOhbTgdLwWh3n7RKgskghQI3rw6ViOcDMHcys5H6DSi7KkomrW1JeQ05ISQUvLZSsNqcBAPMUk7G97rOu/EeNj+U2vG7laLvEv1zQtyHBEYPKeSkgLIU2pSdJ2NnfTY99fzLOJ1owOIJWSoesEdXxXLmpqOlXzDnWNn8lY6Pd3eMOjn2Z6YeMLg1h1vzJWVM2f8A7cLzkkPuSXnEIdcBC3ENKWW0LUCQVJSD1NeFn4G4Pj+Tpv8AbrEmHcUPrko7KS8GG3Vgha0Mc/ZJUQpQJSkHqa9MC4vWTijb5c7E2Z1/iRHzGeehMhaUOAA8p73uIO/A1J/SFw/Fu9/qo+1TR7u4z7O+ELe8nzAH7k5PXj485VLE9HLLfShiR2gc7VlAc5WVlYBKmwknrvYJ3LLJiFnxxi6M2+Ellm5zHp8xC1qcDzzp24ohROgr/hGh7hWR6QuH4t3v9VH2q0tk4hw8ku16tdstt0mXCzPJj3CM3G78ZxSeZKVDfTY6imj3dyYuWY2TDT2TgBgWOuS1W6xGMmTHeiKZE2QWkNOjTiG2y4UtBQ/4An5qkLXD+wMuYwtEDSsZQW7Se2c/2ZJZLBHxu/8AcyU9/m9/j1rY+kLh+Ld7/VR9qnpC4fi3e/1Ufapo93ciK7MbJhFLPwNwfH8nTf7dYkw7ih9clHZSXgw26sELWhjn7JKiFKBKUg9TUmxzFbXiUaXHtMXzRmXMfnvJ7Ra+Z95ZW4vaidbUSdDoPYAK1eYcQYuAY5Lv2Q2y62qzxOUvy34vcb5lBCd6J8VKA/PVRS/Lu4TtSUsNXtYUo/t78V4MJ/KW23FfoQaaPc6Y8Y+JytmnXEwvy5zVQYiltNGRJWezjx0nSnnD8VA/Kf0DZ9lWFitj9W8dgW0uds4w0A47/COHqtX51FR/PVc8AcuxHizZn8tx6/N5SY0lcAym4T0VqK4EIWpttDyQrfK4ja/vt9NDaRv4fE+U3lmV229YrdbBZLFG89TkkrkVBlshIKygpJIUO8eUjek7OtgVM4UU5lM47/rucjKr8Xpwp2QntK0GEZ9j3EjHYt+xm7RrxaJRKWpUdXdUofGTo6II0dggEVv6qaJSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBSozknEzFsQyKxWG83yHb7zfHext0F1f3WSr/lSPAb6bOhsgb2QKiHmGdcUYGf49k0FzAbM48Idku9hugVcHmQpXO/zAaa5glPKNbAWoEdASEnyfivi2H5hjmLXW6Jj37IXFN26Elpa1O8oJKjyghKemtq0NkVGW8bzPihaM7x/PmI2OY/Llea2d3Gbi6ieuKlZJcdc8ElYCO6n71S0qT75zi+IW/E7HZrZGDspNphpgxpc1fbSeyASCFOHqd8id+/lHuFZ95vELH7RNulyktw7fCYXJkSHTpDTaElSlH5gATQaYYJAhcPDiFumXC0W9u1qtUebElqEyI12XZpW28vmUHEjRSo70Ug+yvwo4iwXoGaXptV3fyKMZr6Yt8eSpIubSHltpkp5iei+QnxOjsbOjX7TWS73PjTMwPOcPy5+14ClMiTJtq7aW37orq22FKcG0tfHPRPXSSCdgp2vE7gPhPF6BZImR2RiQmzT27hBcaSG1tLDiVuI2B1bd5eVxB6KB30UlKkhF/I84Rngx5P+M2WQx2F2lNek7kCnSvOHgFFKh70J5G//p1dNKUCq7t0520ccrpaImCoh2662du6S8xjNgCXLQ52KIrxCBtaWxzJJUensG6sSoJxCh5AnKMLu1uymJYLBb5rnpmFN5UouDbjfI2gKI2FJWdgbAJPt0KCd0pSgwL9YrflFkn2e6xG51snsLjSYzw2h1tQIUk/lBNfi/5QPkuX/hFx0YwS3R3LkzfJTaMdfWpKPO0uuBDaCskJC0qUEK2QN97okiv2vrBmWK23G5W+4S7fFlT7cpa4Up5hK3YylpKFltZG0FSSUnlI2CQelBTnCqRaPJuxLhZwmuUOYLpNhqYTMtkORIgGZ1deCnjspK1rdWNgAAKJDadCrvPK4kg6Uk7BHiPnFfVVYeFUzhhZs5uXDFLbmTX+ULkmDkVwfdtwkle3VJSCVI5wpZOj1Vy7IAGg3PEHgnh/EzFI+O3i2KatcaWJ8du2PuQizIHP90SWSnr90WeuxtW9b619SsSy08VbffomY9hhzcIxpWLKgNqDroC+R5L5POk7UNgaBCB41jx+L9qsl/xDEculRrNnV/gect2xntHWFOpA7Vtt7lCTo82t6JCasCgq+HxTyXHMVyy+5/hb1iiWWTyxhZpHpN2fGKgA8lptIUnXMNpPUaUegFS6w8QsfyK049cI1zZZayCMmXbGZh83fktlKVbQ0vSjoLST06cw94qRVGsp4bYvm12sd0vtihXS42SQJVtlSG9uRXQpKuZCvEdUJOvDaR7qCS0qAQOHF4sGaZbk0HL7tcTeI2o1huz3Pb4UhKQErbCQChJ5Uggb8VHZJrSyeIudcN+F8S85viK8pyITTHlweH7C5ISztfK+hDqgojSRsb2CsfPQWzSo4viLjTOaR8PfvUKNlUiKJrVneeSmQ40ebvJTvva7NZITsgJJ8OtSOgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUpSgUrX3PILXZX4LNwuMSC9OeEeI3JfS2qQ6fBDYJ2pXzDZqBOZBlvElnPsdt9pu/DpyCfMrTlU1pl4SnO8FPNMFR2gaSQVfGC/vVAgBL7/neO4tdbRbLve4NuuN3fEa3xJD6UuynD96hO9n3b8NkDxIqFuS814ows/wAeetlw4axWnPMbLkrMpp6TK0Vc8hDQ/a09E8uzshRO0kdJFjnDS32634uq+KTlmQ4/FMaNkN1YQuZtQSFrCtd1SuROyOp11J2SZhQRzGMHhY9aLBGkuvX+42WJ5pHvV3CHpyklKQtSneUHmXyp5iNc2hvdSOlRHifxUxzg9i/p/J5i4kAvtxWgyyp5155Z0httCQVKUdE6A8AT7KDYZ3nFl4a4jdMmyGYmBZra120iQUlXKNgAADqSVEAAdSSBUXscG/5lm9szOPlLiMAl2NHm2MrtwaW869pZdfUvvDSeTSdAjZHhvmzbHiORrznKbtfslRd8XuTLDFsxwwEIaiISna1OFW1LWpSlb8BrWx0SEzmg82GG4rDbLLaGmW0hCG0JCUpSBoAAeAAr0pSg8nZTLCuVx5ttRG9KUAa+PSEX8JZ+kFVhxm4oWzh9drPCehXG83m6pUmDaLQwHpL4RsuKAUpKUpSCNqUoAbHvqH3PjnAtkayNnGckfv8Ad0vOMY41CR5+htpXK444lTgbQgEp0or0rmHLvdBf/pCL+Es/SCoHxuxrGM64dXCJkTM2526Gpu5ebWZRVMWthQcSGUp7ylkp1yjqd6HU1WjnlEY4q047Mh2+83J++TJFuj26LDHnTUphKi6w62pQ7NSShQJJ5RrZIT3qj+e+Ua7A4aP5BjlguTlziX+NYp9tnMNh+E4p5sLStPahJKkOJCFJUpJU4gnu8xAdN2bI4d6s8G4oK4iJbDcgR5qexfaCkhXK4hXVCxvRSeoIIrM9IRfwln6QVzxN4lTH+JPD6zuQr7jibwxMkOQ5cOK40+UNKPYuupeUppaOUOfcwoKC0gnx1j4j5SNgy9WMutWTILba8jc83t12uENDcZ2RyKV2Ow4VBXcWAeXkUUnlUaDo/wBIRfwln6QU9IRfwln6QVQzvHGxM8O52ZGJcTa4dzVanGQ232xdEwQyoDn5eXtDvfNvl6630rFybj7ZsbuN3ZTZb/d7fZVFF2vFrgh6JAUEhS0rVzhSihJClBtK+UeOj0oOikqC0hSSFJI2CPA1/awrJLZuFmgSozqX478dt1t1B2laSkEEH3EGs2gx5TEVS2H5LbJXHUVtOupG21FJSSknwJCiOnsJHtqpl2DIuEOKZjcMSuk3iNdp0/0jBseQ3VCEMBawXmWXinug7cKQegPKPeTNuKOXWrA8HuV/vcoQ7XASHX3ikqIG9AADqVEkAAdSSAKqSPxytzGOXq+37HcjxK2WthEhb17gpb7dKzyoS2ELWSsq0OQ6VtSQR1oLrseTIuNvt6pzPoy4yIjcl+GtfaJjrIHM0XQORSkqJHQ9db1qtn6Qi/hLP0grnQeUXZItvyF672LIMfm2W1LvTlsukRtuTIiJ2FOMgOFCtHSSCoEEjYG6z7Jxvt98vDlqTj2QQp7ttdutuYnRW2VXRhHKD2G3OitrR3HezUOcEgDZAX56Qi/hLP0gp6Qi/hLP0grkKw+UHfb95Ndzza5WK9WSe1BU8blbocV9sbLg7eOy5I76GgkFSXCkn2BVTO6ce7fYZ8+0psWR5DcLTbo1xnOWyE0UpYdQpQcJLqRvuK2gd4/ehQB0F8vWzH5F6j3h2JbXbtHQW2Z622y+2kjRSlzXMAQTsA+2q/jcImMJxHLYHD3KpOOXm+SDNan3J83NqG+Vcyihp1WtK72xs9Vb66ArU4/xVseUZLb7NbTIkLn2JvIY8sIAYXFcWEI6k8wUdg65da9u+laFvygrFMx+03G32q9XWbdZMyPDs0KMhcx3zV5TL7mu0CEtpUkd5SwO+n2nVBYL2T59i8XA4Ax5jPHpim4mRXuBMahtwFnswX0sqBLiNqcJSnRASPfqttY+MeKZDxByPCok9z1hsDSX57DsZxDaGlBJCw6U8hHeA6K3sK6dCa8ODef27iHjs6ZAZmQ3oc5yFMg3BnsZEV9KUFTbidkb5VpUCCQQoEE7qaT7dGukORFlsofjyGlMOtrHRaFDSkn5iDQfcSYxcIrUmK+3JjupC23mVhaFg+BBHQivaqovPACJbuGzGI8OL5N4XtRpxuDMmzDte+eYqQtLhPO2oq2U7HxUjwGqkUyXnsfiZaYsWBZpeAOQyJk92QtNyakgLIIQAGyhR7IdOo756DQoJrSq8x7jbZ7pbspuF4tl3wuBjsox5cvJ4ohtOJ3pLzaiohTahohXT4wqc2u6Qr3b48+3S2J8GQgOMyorqXGnUnwUlSSQQfeKDKpSlApSlApSlApSlApSlBVfEd3Gn+M3C223nCzf7rIVcH7Ze1shxq0LZaQ4pStjQUvSAk+IUkEdRVqVDMn9dvhIwr0J5l6mam+sPba7ffZDzXsvb+2b3r2VM6BSlKBUHy/1we4jYRGtdtt0zClmW5f35QSXmFobSqGWgVDr2oOyEnWh4eNTiq2ze1QpfGfhpNfzVdlmxE3PzfGku8qb3zMJCyU8w5uxHf8Aiq1v2eNBZNKUoFKUoKB45Y1ktt4tYtnuM2dGTLg2yTaZto86bjvKaecQtLrK3CEcyVNaIURsHoaiNzg5yznlh4kR8JMmcq0yrJcMcRdI/nDDapCXWXkOqKWlE8mlp5hrmGirVdRSrbGmOBbzfOoDQPMR0/Ma8fQMH+A/tq+ug5Jw/hDlttyXB75coLKJLmVXjIruxHkoW3bkyojrbbQUSC4QS2klIPeJPh1r6yrhLldyx/iomFbm1TbhlUG+2lh2ShKZrcdMNRTzAnsyosOJHPrronod11p6Bg/wH9tX109Awf4D+2r66DnmdaMlzDiDwtyaVjb1katarp6RjPy2HVxQ4x2bWyhZC+Yj7zet9dVEcd4U5TA4OcGbG/a+S649foc25secNHzdlBf51cwVyq1zp6JJPXoPGus3LFDDauSOCvR5QpagN+zfWojwoF+yHDWJWb4wzjWRB99p+FGlF5kpS4oIcQoKJ5VJCT10fHoOlBzBkHDviCxw3yHAIGIiew/kpujF5FyjoaciruaJfRClBYcSNgpUAnSSQonST9r4HvY9m+XGbwjsfEaJfLw9dod8lPxW1xkvkKWw+HQV6QrmKSgL2COgNdl+gYP8B/bV9dPQMH+A/tq+ug+rHDYt1lt8SKyiPGYjttNMtJCUoQlICUgDwAAA1WdXy22lptKEjSUgAD5q+qCr/KUwa4cROEV0s9odYauokRZsTzrfYrdYkNvJQvX3qi3yk+ze/ZVSZvb864ycPLxaJmFpxG4x1RJ8EzrqxJbkyWJCHuyPY702ezCedWj3t8o1XU0iM3La7N1POje9bI/urE9Awf4D+2r66DjziHgWe8X/AFovMvFPVx5rEJ9jttqduMd5+bKklClKK0K7NLY7NIHMoElWyBViTcLvLvFPhleEQ926z2a4xJ73ao+4uupihtOt7VstL6pBA111sbtziE89jGHXq42DHV5PfYcYvRrMxJDbkhW9JG1HoPE+8hJABOhWfjNoemWO3Sr1bkW67PRWlS4DEgvNR3uXa0pXoFWidb8O6NfOHK1lwHOI/k0ZRwylYupu4xLPLt9unNz46mbmpanOzKBzhTewpO+0CdE1MsZwO+W/O8/uEiD2cO6Y/aoMRztmz2rzLclLqdBWxouI6kAHfQnRrov0DB/gP7avrp6Bg/wH9tX10HImBYFm3DN/h/eG8WXe34uFs45cbexPjtOw5CHEuBRUtYQtHxkkoKiNAgGonbfJ/wAlhWHB7zfcEtmXTLYu8R7nisqSwsdnKnOPtPsOOHsypPT4xSSleuh2K7n9Awf4D+2r66egYP8AAf21fXQQXgBjkbG8GW2xhkDA3JEtx960QFtLSlXRKVqU0AkrKEo3revDZ1urKrxixGoaChlHIknZGyev569qBSlKDDvFmt+Q22RbrrBjXK3yE8j0SYyl1pxO96UhQII6DxFQzgqjKIuKy4GT45a8WFvuD8O0wLQEpY9HIIEZfKlxYSSnxG0618UVP6rrgjafRFivzfr98Ifa3yY9572/beZcyh/sW+1c12Xhy7Gt/FTQWLSlKBSlKBSlKBSlKBSlKCss6tVkl8bOGE2dlb9qvMRN09HWFC9N3YKjpDpUPb2SdLH5as2qyzq62SJxs4YQp2KP3W8y03T0dfkI23aQmOkuhR9nap0gfkqzaBSlKBVXZ7dcWi8c+FkK6Y9KuOTS0XX0NeGt9lbgmOkvhzvD9sRpI2D1Hsq0ahmTys2a4kYUzZIcJ7DHUzfWGS8QH2SGgYvZDmBO3NhWkq6e6gmdKUoFKUoFKUoFKUoFVNxQ9CcKcme4w37I73CtNutYtUy1xgp+I4HH08jpaAPKoKVoqTy+zZ0CDbNcg/shWFcZcxw+MnApK38PjsLVeLRalLRcJajzA82j92ZCDrsk9SSSpK9J5AvO2+UZw/vnFOFw+tOQxbzkMmI/LItriZDDHZKALTjiCQl098hHiA2rm5eZHPZdfjb+x8yF27yu8MZcBaLiZ7K0qGiD5m+dEflSK/ZKgUpSgVD+LGZ3bA8Hn3ew4zMzC8tltqNaIKglbq3FhCSon4qATtStHQBPgCR8cVeIMvhxj0W4QMXu2XzZU5iC1b7QgFYLitFxald1CEgHvK0NlIJAOwxDhZa8PzLLMpjy7nMu2SvNOSjOlqdbZQ2nlbaaR8VKE7UR4nvEb1oAPPGeF1mtee3biAqHJayu+Qo8WX5xLU+mM2gA9i0PipTzDZ5ehI37TU3pSgUpSgUpSgUpSgUpSgVVPk63TCbtjWSuYLZ5tmgN5HPZnNTllSnZyVjt3U7cc7ijogbH8UVa1QvhZdM2u1puzmdWeFZp7d1kswWoKwpLsFKh2DqtOOd9Q2SNj+KKCaUpSgUpSgUpSgUpSgUpSghmT+u3wkYV6E8y9TNTfWHttdvvsh5r2Xt/bN717KmdVlnVqskvjZwwmzsrftV5iJuno6woXpu7BUdIdKh7eyTpY/LVm0ClKUCq2ze1QpfGfhpNfzVdlmxE3PzfGku8qb3zMJCyU8w5uxHf+KrW/Z41ZNVdnt1xaLxz4WQrpj0q45NLRdfQ14a32VuCY6S+HO8P2xGkjYPUeygtGlKUClKUClKhXEa7uFUGwx1ltdwS47JWkkKTGRyhQBHgVKWhP5OcjqKzopz5wZ0UTcqimOl8XriFIckOxcfhtzFNqKHJ8tZRHSodCEADmdIPQ65U+Pe2CK0q7xljvVV+itKPsj24BI/Mpaj/ANa+mmkMNIbbQlttACUoQNBIHgAPYK+qnl83VRERHfET7fc71GSWqY1xi8fSeV/jGj+r2/rp6Tyv8Y0f1e39dfNym+jbdKl9g/K7BpbvYRkc7rnKCeVCfao60B7Sa0tuzy2XC7Wi0rTKg3i52w3Zu3y2FIeaZSW0qDniErSp1KSne9791NIr3R6tPwZ8hZj9MInO4EWubxWtvEcOx4mXwVrcE+JCS126lNqbJdQk8qzpR7xG/DZIGqsj0nlf4xo/q9v66wbbffSN5u9v9HT4vo5baPO5LPIxK50Be2Vb74TvlV0GlAitpTSK90erT8E6PZn9Lx9J5X+MaP6vb+unpPK/xjR/V7f117UppFe6PVp+Bo9rqorieLX7D7jfp0fMLhOk3qX55JVcU9ulKuXlCWkE8raQkAAJA6AA70NST0nlf4xo/q9v669qj+U5vBxK5Y5CmNSHHb7cPRsYsJSUoc7Jx3a9qGk8rShsbOyOntDSK90erT8ETYsxtpb1u85awrmTfIkgj7yTbhyn+gtJrf2HP1PS2YN7iJt0l1QbZktOc8Z5Z8EgnSkKJ6AKGidAKJOq0deUuIzOjOx5DaXmHUlC21jYUD4g0i9narkRh3RET4YeKuvJLVUaowladKiXDy9vz4Uy2zXi/NtrobLqiSp1lQ5mlqJ8Ty7ST7VIUfbUtqK6cyrBwq6ZoqmmegpSlYMClKUClKUCq64I2n0RYr836/fCH2t8mPee9v23mXMof7FvtXNdl4cuxrfxU1YtVT5Ot0wm7Y1krmC2ebZoDeRz2ZzU5ZUp2clY7d1O3HO4o6IGx/FFBa1KUoFKUoFKUoFKUoFKUoKyzq62SJxs4YQp2KP3W8y03T0dfkI23aQmOkuhR9nap0gfkqzahmT+u3wkYV6E8y9TNTfWHttdvvsh5r2Xt/bN717KmdApSlAqGZPKzZriRhTNkhwnsMdTN9YZLxAfZIaBi9kOYE7c2FaSrp7qmdVtm9qhS+M/DSa/mq7LNiJufm+NJd5U3vmYSFkp5hzdiO/8VWt+zxoLJpSlApSlAqssq5vhKkc++T0RH7P3b7Z/n/8AZVm1CuItoc3Bv0dBcXb0uNyUJBKlRl8pWQB4lKkIV79BYHU1da140b4w9/jhg2cmrii7Ey0bxWllZbSFOBJKUnwJ9lc6eTnaMFvWO45ll5lxJnEuS+759LnTSmcJpUsORygqBASNgNa0AkED210Y06h9pDrS0uNrSFJWg7CgfAg+0VpU4HjSMhVfk47ak31R2bmILQkk611d5ebw+etTY9BVTjMS5w4ecLsXuHkvZHfJ1nj3C7SYV75pUpPaLQlEp9SEI38VIU0hWhocwJ8Sa/tjxbEpXEvhDNyS3WtSHsCStmRcEIAXJZMQtkKV9+hKlke0AmumouO2qFZ12mPbIbFqWlxKoLUdCWFBZJcBQBykKKlE9OpUd+NYl1wbG77b4UC5Y/a7hBg8vmkWVCbdaj8o0ns0qSQnQAA1rQqcVXI4RHdg5ezhtrFL5xbiQlqsWOzMvsLd8lQlFksQ5EdlUpznT1RzqWeZQ/41V0Lw0xfAsUVcY+EN2yP2gaclsW2SHQNhXZrUkKPLzd/vdObR8dVJ/V61dpcnPRkPtLnrz5XYI3L0gIHanXf0gBI5t9BrwqPO8MoFstwiYg8jAQp3tHl49boaO36EaWlxlafbvYAPz1DKm3NE47fqUa8qgqTwDywoWttYbYIW2opUk+cNdQR1B+cVWPEq0OcJ8uzKLw/jLtDsnh/MuCmIalErksyEITI1s7dCHF974xOt7q8bfw9lqL7GRZRPzG1vt9m5a7zBgGOo8wUFENR0EkFPQE6+bYGpQq0QFXVNzMKObklgxkzC0ntg0VBRbC9b5SoA8u9bAPsoVW8+cdn1LlqWxYsAyLC3+EbrUu6XGwXSRObhSDIM1CIRcjvyE7VtfnAbAURslak/MNfjFhwdtfAbILHMj3LJ7rdm3rncFTS9LlOKgvqeLwKidpc0Oo7m+Ua3o9TWHCcdxWRKkWWwWyzvyjuQ7AhtsKePvWUJBV+esaJw2xGBdfSkbFrLHuXbec+eNW9lL3a6I7TnCd82lKHNvfePvow5Ge76w2cHKPDXDp3EK2wsjn5njNizpd5UmVJkRpHpmPKRJIMXmMwJ5SlPIG+y5ShQ0n212jWjXgmNOZCL+rHrUq+jWrmYTRkjXQfdeXm/61t5ctmBGdkSHUssNJK1uLOgkD21OEzOELLdHJwzsE5/Xu8cu+z9Gxef3b7V/l/91WLUS4eWR+BCl3KayWJ1yd7QtKBCmmUjlaQd+B5e8R7FLUPZUtrauz97DdERwhwL9UV3aqoKUpVLXKUpQKUpQKhfCy6ZtdrTdnM6s8KzT27rJZgtQVhSXYKVDsHVacc76hskbH8UVNKrrgjafRFivzfr98Ifa3yY9572/beZcyh/sW+1c12Xhy7Gt/FTQWLSlKBSlKBSlKBSlKBSlKCss6tVkl8bOGE2dlb9qvMRN09HWFC9N3YKjpDpUPb2SdLH5as2qyzq62SJxs4YQp2KP3W8y03T0dfkI23aQmOkuhR9nap0gfkqzaBSlKBVXZ7dcWi8c+FkK6Y9KuOTS0XX0NeGt9lbgmOkvhzvD9sRpI2D1Hsq0ahmTys2a4kYUzZIcJ7DHUzfWGS8QH2SGgYvZDmBO3NhWkq6e6gmdKUoFKrSXx6sN0w/KLzg7bvESZYH0xH7VYe+8t8qSORJVoEAK5iobGkq1sjVfUtPEnKpuA3W2Sbfh1pU2mVklluEfzqZshB82bcSeQa24krGiCEkb2QAn12u0Ow2qZc7jKahW+GyuRIkvqCW2m0JKlLUT4AAEk/NVbXvju1MwmwZNw+x2fxLg3ieYTS7MpLaGglS0uOuKc1yoSW1DZGidDY5gTuMd4MY/juXZdkQcuFzm5QA3PYuctUiMGhvTSGld1KO8roQfjEeB1U0t9uiWmEzDgxWYURlPK2xHbDbaB7kpHQD8lBD71w9fRIdlWCY3DU4orcgykFcdaj1JQQQpsk9TrafE8uyTWmXZstZ6KsUR5Q9se4gpP8ASQk/9KtGlXcpj+OmJ4+6Yx/ttUZVdojCJVX6Myz8XG/6wb+qnozLPxcb/rBv6qtSlM+js4/18Vmm3VV+jMs/Fxv+sG/qqO8QssuPC7DLrlORWdqFZ7a12r7vn6FHqQlKUgDqpSilIHtJFXtX5wfso/HUzLrauFlrk/cYgRcrwEHxdUnbDR/IhRcIPQ86D4ppn0dnH+viabddbYpdb1muNWu/2eysy7Vc4zcuM+J6BztrSFJJBGwdHqD1B2DW19GZZ+Ljf9YN/VXLf7Fzx09LY9deF1ze3JtnNcbSVq+NHUr7s0P4q1BYHie0X7E13xTPo7OP9fE026qv0Zln4uN/1g39VPRmWfi43/WDf1ValKZ9HZx/r4mm3VXN2XLXzypskKPv7+Tceg/MhtRNSCw4ApmWzOvUtNxktKDjMZpvkjMrHgoJO1KUD4FR0OhASRupjSnKYfgpiPRj75nwV15TduRhMoVmrPEFWV4s7iciwIx1D5F+ZuyHjJcZKkaMYo6BYAX8Y62oeOtHGi8UZTWU5bb71id2sNlsMYzUZFJ5FwpjITtRQUkkKGlHlI3pOzrYFT6lUtVGME4l4xxMxiFkONXhm6WeastMSUhTfOsEgp5VgKCho9CN9DUnqFcQODOG8T8VbxzIbG1Ks7coTm40dxcbs5He+6JLSkkK2tZ8epUSd1/ZWE35XE635HEzKZDx1iEYknFhFaXGkKHPyuhw95CgVpJKfEISPDdBNKVV9tzbP8Zx3MLvmuJszE22QVWqFh5XMlT43N002vR7QAp2Om9KOgK3ULjFiy7Visy63FGLv5OgKtlvv6kxJTyjy/c+RR+P30Dl2TtQHiaCbUpSgVVPk63TCbtjWSuYLZ5tmgN5HPZnNTllSnZyVjt3U7cc7ijogbH8UVa1QvhZdM2u1puzmdWeFZp7d1kswWoKwpLsFKh2DqtOOd9Q2SNj+KKCaUpSgUpSgUpSgUpSgUpSghmT+u3wkYV6E8y9TNTfWHttdvvsh5r2Xt/bN717KmdVbxTi4/aeJPDTLL/lzuPej5kq2QrcpZTHuciWz2aEOfOnkKk76b91WlQKV/FEpSSAVEDwHiaqex5/nnErHc0ZteGTOHl5gnzezy8rCHG5TneClltlStJSUjvBSkq5gQVDYoLZqj8yzPFb1x/xeHBz9YynFY1xeewiAslV2LsbaUK7yUFaEp50pOz133R1rfzOCq84tmBv55fpt1yDGHUzVv2h5UCLMlBSFJccZQe8ElCSB00ebwCiKxctj4VbfKBwDt8OXLzK4t3B6LkMRkJTDCIyUOGQsEcxW2A2nmCtcuhqg8H77xQ4rcKoc7GIDfCrJZM4hxrJmBLdahjmHOltPQOK7h5VjppQPsVUqk8IrTP4p27iBLmXN2+QIJhMRkzVpgoBCwtwMb1zKCyDskd1J1sbqcUoMG02O22Flxm2W+LbmXHFPLbiMpaSpajtSiEgbJPUnxNZ1KUClKUClKUClKUCqr4x8LsVmY9keUt8LsZzbMERFOsN3C0R3n5rqEBLbanFIKj0SlI69AAPZVqVVvGPiHbWFM8O7flHq9n2VQ3kWN5LDjnZLCFEPFSUlKQCnXU9SRqgzuHHCXC7HCseQxOHOM4pkpiNuuqt1ojsPxHVt6dbS4hAUNcyknr1G6sStbjMGbbMctUO5zPSFyjxGmpUvWu3dSgBa/8A1KBP562VApSlApSlApSlApSlArV3rFrNkb0B67WmDc3re+mVDclx0OqjPJIUlxsqBKFApB2NHoK2lKCDweElqsue5Hmlql3CJf75FEeQHZbj0TnSlCUOiOpXLzJDaB010BHTZqNuL4scNeFadNxeMGZMS9Hl7KzdvG952ShKwB7PEn5qtylBB53Fq1WbP8dwq6RLhFv97iGTGLURx6JzJStS2jISnlCkhtZ666aPTYrW8DYjFstWRw0cRG+Ir4vcp9yQmUHlW8LVtMM/dXCns9EAbT7e6KsqqC4PYbwzzPFOJ0HB7PdcMVPvUyzX+Q0+pqaqW0o9ottZcc5Rt1RTrWuY90UF+0qsp2GZ7i9gw604ZlEe4N218IusvMe0lyp8YkbPao5T2oBUQegJCQdDdbi35xfpXFS54vIwufEsMeImTGylUhtUWUrTfM0EDvIUCsjR8eRR8NUE1pSlApSlApSlApSlBrMgxm0ZXCbh3q2RLrFbfbkoZmMpdQl1tQUhYCgeoIBBqP8AC67ZpdLLcPXuywbLdmLlIYj+jpHasSooX9xeTslSdp6EK0e7vSd8omdUV5S2V8MuFt0w3iDnV7nWm72N2UbPEtjii/cipk9rHLSR30HubUopQlRQFLSF6IXrVccK4UbGMhzfH3c6dy27quq7y5BlvFb9ojyQCzG6rUQ2kIPLvXQ+ABFcP8KfL+4kcTeOr78fG2LpEFnnt2rDIEtcdL5SpMgrW6UrLsgMsKSFcmjpQQhBcUTUmZ+X7n1yzW8ZJjNoseD3uepDD1xhxlSZjkVsr7KO6X1LaVy8w2tLKFEoHxRtNB+wVQq1evCuLN9M/wAyRgKbfHTbUo0ZC5XMS6pR8QANDR2D0I9taDyZckyXJfJ+w7IM3uSbhfrhBVPkzSy2wFNuLW40eVCUpGmi2OgG9b9te/AS3Y87jt5yrGMln5TaMtu0i9My5pUA0FkILLSVJSUtoUhQAKQep3vxoLNpSlApSlApSvORJahsOPvuoYZbSVLccUEpSB4kk9AKD0pUByzjJacak4i1Dt11ylGTSRHiScdi+eMNI2kKfdcSrSWkhfMVDfRKtA6r+xonEC7ZxlES7OWe34G5D83tT9sddF1Lykp5nVkjkQE7WE8vXaQaDd5zxExnhpaEXTKr7BsMBboYbfnPBsOOEEhCQeqlaBOhs6BPgDWtczy7fCo1ibWG3Zdo8yMt7J1FCYSFnfK0nrzLUdEEdCnu9CDuvDGODVgsWF27GroZWaxYMlU1uTlbibhIMglR7UqWnXMCteiANcx1U6AAAAGgPZQVGzwgyDiJw0vWL8Xb9GyH0nND+rAyu3ojsJUgpYCgrmWCUHZPXTihs6BqzbNYYFgt0CDBjhpiDGRDj86i4tDKAAlJWolSuiR1JJOtnZrYUoFKUoFKUoFKUoFKUoFKUoFKUoFKUoFQzHZeaHiTlkW7W6A1hSGoq7FNjEB9xwoPnKXk85J75BB5UjXv8akeQTJ1vsNylWu3i7XNiM67FgKfDAkupSShouEEI5lAJ5iDre9HVfk5xk8vviffOKPpayx1cPZFqZctqbXzqlKaJUnte2Q6kNqcC0KAPZJKUq11KQqg/XOqqultxXNPKGsb6cimHLMKtz7yrI0lQjpamJCO0cVy6KiEjQ5vYDr21x/cuO/GvHvIntfFNjLnnsgveUKckzHoMdzsYQaVGQ2hpSC02jtI4UQlAJU5zb2pXNCuDv7IVxGm8QbawOHeM5ZfrslmBLetcRcK63ZSGylouPhSkAhR5j9y5QOYAIGikP1KpSlApSlApSlApSoNluUSZdwds1qfMZLGhOnI6rQSAQy37llJBUs/FBAAKlcyM6ac70Qst26rlWbSkN5zCx46sN3K7Q4TpGw068kLI94T4n9FUJ5RHCfg75SUSM5kFxXBvkNstRL1b2lJfQgnm7Ne0EON8xJCT4cyuUp5lEzuBaolsSoRmEtqV1W4dqWs+O1LOyo/OSTWVWWfZjVhM/3EeGE+11IyCMNdT88OHPk9ZL5PPlJ4PfoUyNlWNR7s2h27W5K0KZjuHs1rdaUApOkLUTy8yQB8Y1NPLY8mey5rmEXNOGrrT067S0tXm1oQW0BxZA87TzAAAn9sG/Hva6qI7bpTPs9WeMeVloFPWanL+K2N8OeEUmPj0D1sXa7c3DiWBtC0GWhIS2G9lBAHL49D0B6Gt9hmdYPjWK2u224xbDDYYSEWyKyvs4xPeUhOkAEAk9QKx6Uz7PVnjHlNAp6yQ/Cvinyuj6Jz7Nf0cVsTPjeWUD/icQtIH5ynVR2lM+z1Z4x5TQKessG13m33yN5xbp0eexvXaRnUuJB92wfGtRxD4h2HhZiczJclmLg2eIUJdeQw48QpaghCQlCSokqUlI6eJFQd20tiWJsRa7fcU/FlxjyrPzLHgtP/ACqBFTnEMnOQsPxprTbN2h8vnDTfVCgSeR1G+oSrlVoHqClQ2dbKaaaozqOjbG74tG/k1VnXthopOZZddMsxAY3jMWbhVziee3G+TZnYPRkqTtttEcp5is7SevT4wPKdGvC1cIX5C84YzHJp2cWbJnClNmuLLbcWBG2vlZaSgA+CwCvezyJPQ7NWPSqmm19gx+2YpZolps1vjWq1xEdmxDhtBtppPjpKR0HUk/lNbClKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBWBe77AxyAqbcpKYsVKkoLigSOZR0B069Saz6hfFf97sH+dIf+MmrLcRVVETsY1VZtM1bnt8LGKfK6PoXPs0+FjFPldH0Ln2a0tK52n2uzn1o8rzHPc9n4/JuvhYxT5XR9C59muKfLr8n7HuLj7eb8P32XcwKm2LhbkpLKZ6OiUuhSwlIcR0BKiAUjx2kBXXlKafa7OfWjynPc9n4/JTGd4rjt38i9zhdDnNSLxGx+OyyylCkdrNYCHQAogJTzuoI2SB3js6qD+QpwTxTgfZDluXS2TndwQUtsqaWv0YwfvAQkjtFffKHgO6Pvubp+lNPtdnPrR5Tnuez8fk3XwsYp8ro+hc+zT4WMU+V0fQufZrS0pp9rs59aPKc9z2fj8m6+FjFPldH0Ln2akVpu0O+25mdAfTJiPAlDqN6VokHx+cEVA63PCf94cD+Vk/5hytq1eov0VVU0zGEx047ce6Nzp5Dl2mTVGbhh3pfSlKzdZ4zZSYMN+Sv4jLanFfkA2f7qqLFwtdhiSHjzSZaPO3160VOOd9R/So1bs2KmdDfjL+I82ptX5CNGqixcrRYYkd4csmIjzR9G9lLjfcUP0p3+cVbP5M4b49kurkGGdVvaHiTxHOCCzQoVqdv2QXuUYlttbLqWe1UlBW4tbithCEISSVaJ8Oh3WsvPEPLMfwdy83HD7fBuTUrsXYsrImWojbPLvt1SVIGk77vLyc2z4a6168VcBvGTT8YyDGpkOJkuOSnH4qLklRiyG3Wi0804Ud5O0kEKAOikdDUby/h9nmbx8Yul1axWReLHdnJyLMt2Qq3PtKYLaedwtlRdQpSlpV2evAa9taro1TXjOCPzuNTnEbHcButpcds7vr1Hs1xYhTw805yodK0B5shLzSgUKB8D06dKnPDO7zp/E/ixFkzZEmLCukNuKw66pSGEqgMKUlCSdJBUoqIGtkk+2oO1wJzSPYbgUTsf8ATicway+EEJeREUvskocjuDRUhI0oBaeYnoSlPhUyi2uZwv4gZplFweTJxnIVxX+ygwpMqcxKQyhjl7NltfM0Ut83N0IPQjXWpYU52MTV9apTjNrjcLRh96nWplt+4x4brsdt5zs0lYSSNq5Va9/xTVSYXxpyO2cFsMvGRWNu55FfkQYdqYhzwpd0eeZC+1dJaQmP0StagOcJAOiegqfReImP50p2wxkXxp2cy6zzyrBPitgFB2S46wlCem9bI2dAdTqq8tvBzO2uH2LWaTMx5u74TKiP2GYwp9TctDLbjKkyklILfO0sDuFWj19mqhnVMzONEtvI8oddiiXyFf8AF34GXW6TCis2OJMRITPXLUUxuxeKUDSlJWFFSRy8h6HpvQcUOL99Vw44k2W5Wp/C8wtlgVdIy4Fy84S4woqQHWn0pQpKkrSUkFII2CCQd173PgRlOWyb3lF6udphZs7Ltsu1NQg49Bh+ZLUttC1KCVuBwuOcx5RrmGh065F34JZPxFTmtxy6faoF4vWPnHYMezl16PEaKlOFxa3EoUtSnCnYCRoJ113up1K55SYw+uldduUpdviqUSpRaSSSdknQr6hSTbM0x+Sg8vnTjkB3Q+MhTanE7PzLaTr+MffWDirN1j45bWr35p6WbYSiSYBUWCsDRKOYBWvyis6DGNzzTH4yBzCK45Pd0fioS2ptO/yrdTr+KfdV+T/j/qfZLO/hyNWO5alKUrB5opSlApSlApSlApSlApSlApSlApSlApSlAqF8V/3uwf50h/4yamlQviv+92D/ADpD/wAZNW2vxwqu/l1eiWrpWuv9+iYzanrjNTJVGa5QoQ4jsp3qoJGm2kqWrqR4A6HU9AaiHw54uP8Auck/+1Lr/wDrV5SKZnZD5vTRXVGNMYppeLtFsNonXOc6I8GEwuS+6fBDaElSlfmAJqj8N8rS15RktggPQrXGhX98RoK4eQxpk1taklTYkxW+8zzAa6KXyqICtbqa3DO8W4l2yfiam7+hu9RXoC1PY7cIyQhxtSVbccYShPQnqogVgcLcR4gYkmz2W+KxWbY7VH82TcoaHhPlJQjlaUpspCG1dAVEKXvrrW6spimInOjW2aKaKaKuUjX36uDUY15RNyvULFrzNw023Gb/AHMWdmeLml15uQpxbSCWQ2PualoKebmCuu+XVRbjhxtyO78Os4exCxSmbFapHo5eUtXQRXg+28hDpYaA5lISraCvnTvvaB1UotfBC+wuFOCYyuXbjPsOSR7xJcS452S2W5q31JQeTZXyqAAIA3vrrrWgyfgXxBOGZdg1hm427il4nOzoki4uPty4vavh9xkpQhSVJC+bS970eoNW08nnY97Zo0eLmdGGqe/DDHb6cP8A46NpUHn8Zcctk+TDfZyAvR3FNLLOM3J1HMkkHlWiOUqGx0UkkHxBIrwPHHFx/wBzkf5sVuh//GrWzatzn8lc6s8E/rc8J/3hwP5WT/mHKjVourF8tkefFD6Y76OdAkx3GHNf8zbiUrSfmUAakvCf94cD+Vk/5hyuxkH5Vz00/wDp6H7F1VXInu96X0pSt56oqDZbi8qLcHbzaWfOA9ozoKNBbhACQ8371hIAKT8YAaIKdLnNKzpqzfRKy3cqt1Z1KpoF2iXMK83eStaOi2lApcbPhpSDpST8xANZdTe84jZMiWF3O0w5zgGg48ylSwPcFa2P01qfgoxP5Ga+kX9qssyzOvGY/qJ8cY9jqRl8Ya6UepUh+CjE/kdv6Rz7VPgoxP5Hb+kc+1TMs9aeEeZlp9PVR6lSH4KMT+R2/pHPtU+CjE/kdv6Rz7VMyz1p4R5jT6eqj1KkPwUYn8jt/SOfar+jhTiQ8bIwsf8AC4VLB/MSRTMs9aeEeZGn09VD3Ls2uX5jDQu43I9BEjDmUPnWfBtP/Msgfn6VOsPxZWPsPyJjjci7TOUyXWxpCUp3yNI315U8ytE9SVKOhvQ21ss8CyRvN7dCjwGN77KM0ltO/foAVmUmqmmM2jp29/waV/Kar2rZBSlKqaZSlKBSlKBSlKBSlKBSlKBSlKBSlKBSlKBUL4r/AL3YP86Q/wDGTU0rAvVigZFAVCuUZEuKpSVlte9bSdg9PcRVluYpqiZ2Maqc6mad6DUrd/BRifyO39I59qnwUYn8jt/SOfarnaBa7SfVjzPMcyT2nh82kpW7+CjE/kdv6Rz7VPgoxP5Hb+kc+1TQLXaT6seY5kntPD5tJSt38FGJ/I7f0jn2qfBRifyO39I59qmgWu0n1Y8xzJPaeHzaSlbv4KMT+R2/pHPtU+CjE/kdv6Rz7VNAtdpPqx5jmSe08Pm0lbnhP+8OB/Kyf8w5X18FGJ/I7f0jn2qkNptMOxW9mDAYTGiMghtpHgnZJP8A1JNbVqzRYoqppqmcZjow2Y9873TyHIdDmqc7HHuZlKUrN1ilKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUClKUH/2Q==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## now finally invoking the function on a specific query\n",
        "events = graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=\"Construct and debate the various category of topoi argument\"\n",
        "                \"on the topic: Israel and hamas war and how the israel's legitimate right of defense is countered by palestinians accusation of genocide?\"\n",
        "            )\n",
        "        ],\n",
        "    },\n",
        "    # Maximum number of steps to take in the graph\n",
        "    {\"recursion_limit\": 4000},\n",
        ")\n",
        "for s in events:\n",
        "    print(s)\n",
        "    print(\"----\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "xtMtgwkSNeS1",
        "outputId": "6c0367c2-8576-4a60-c141-f65f085cf9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-7ccd1feba143>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"recursion_limit\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m                     \u001b[0;31m# panic on failure or timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m                     \u001b[0m_panic_or_proceed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minflight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m                     \u001b[0;31m# don't keep futures around in memory longer than needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minflight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1538\u001b[0m                 \u001b[0minflight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0;31m# raise the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minflight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;31m# if successful, end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2500\u001b[0m                 )\n\u001b[1;32m   2501\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2502\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2503\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2504\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maccepts_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-1b41006e0cf8>\u001b[0m in \u001b[0;36magent_node\u001b[0;34m(state, agent, name)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Helper function to create a node for a given agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0magent_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# We convert the agent output into a format that is suitable to append to the global state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToolMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2502\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2504\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2505\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4571\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4572\u001b[0m     ) -> Output:\n\u001b[0;32m-> 4573\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   4574\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4575\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         return cast(\n\u001b[1;32m    169\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    598\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         flattened_outputs = [\n\u001b[1;32m    458\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 results.append(\n\u001b[0;32m--> 446\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    447\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    672\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_message_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 640\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    641\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         )\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 931\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    932\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1016\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1064\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1015\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1016\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1064\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ]
    }
  ]
}